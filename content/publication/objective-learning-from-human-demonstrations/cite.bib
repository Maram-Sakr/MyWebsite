@article{LIN2021,
title = {Objective learning from human demonstrations},
journal = {Annual Reviews in Control},
year = {2021},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2021.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S1367578821000213},
author = {Jonathan Feng-Shun Lin and Pamela Carreno-Medrano and Mahsa Parsapour and Maram Sakr and Dana Kulić},
keywords = {Reward learning, Inverse optimal control, Inverse reinforcement learning},
abstract = {Researchers in biomechanics, neuroscience, human–machine interaction and other fields are interested in inferring human intentions and objectives from observed actions. The problem of inferring objectives from observations has received extensive theoretical and methodological development from both the controls and machine learning communities. In this paper, we provide an integrating view of objective learning from human demonstration data. We differentiate algorithms based on the assumptions made about the objective function structure, how the similarity between the inferred objectives and the observed demonstrations is assessed, the assumptions made about the agent and environment model, and the properties of the observed human demonstrations. We review the application domains and validation approaches of existing works and identify the key open challenges and limitations. The paper concludes with an identification of promising directions for future work.}
}